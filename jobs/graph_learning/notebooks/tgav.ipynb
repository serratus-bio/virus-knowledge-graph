{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T. Gondii Virome Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virus nodes\n",
    "\n",
    "- Only use sOTUs\n",
    "- All non-centroid palmprints are collapsed into their associated centroid. Centroids aggregate relationships associated to non-centroid palmprints\n",
    "\n",
    "#### Host nodes\n",
    "\n",
    "- Only include Taxons with 'family' rank (+ some exceptions)\n",
    "- All taxons with rank = 'family or rank more specific than family are collapsed to ancestor taxon with a family rank. Any taxons with a missing family ancestor are added directly with display label `Unknown`\n",
    "- Remove 44,092 unclassified taxons (metagenomic, environmental, children of TaxId '12908') \n",
    "\n",
    "\n",
    "#### HAS_HOST edges \n",
    "\n",
    "- Edges include SOTUs and Taxons directly associated with SRAs from Toxo dataset\n",
    "- Edges aggregate count by summing multiple SRA associations, and aggregate weight by averaging `percentIdentity` from non-centroid Palmprints and non-family ranked Taxons\n",
    " \n",
    "\n",
    "#### Nodes of interest\n",
    "- Toxoplasma gondii has family `Sarcocystidae` with taxId `5809`\n",
    "- Palmprints associated to Ruby and Cougar strains can be filtered by using node property `point:isRubyOrCougar` or by palmId `u658323` or `u380516`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Community Detection\n",
    "- Label propagation Algorithm (LPA) nicely clusters communities of Taxons and associated palmprints (`point:communityId`) and can be used to color the Virome\n",
    "- Transitional palmprints with edges between diffent communities are of interest\n",
    "\n",
    "#### Centrality\n",
    "- Centrality algorithms measure the spread of influence of nodes in the network\n",
    "- Page Rank highlights nodes with high importantance (`point:pageRank`)\n",
    "- Degree is similarly useful (`point:degree`)\n",
    "- CELF allows specifying count (seed) of k most important nodes in the network, which typically highlights high degree Taxons (`point:celf`)\n",
    "\n",
    "#### Transitionary nodes as potential parasites\n",
    "\n",
    "- Ruby and cougar have Palmprints that are transitionary nodes between clusters, i.e. they have edges between two Taxon families Sarcocystidae, the parent of T Gondii (5809) and Hominidae (9604)\n",
    "- It may be of interest to analyze other transitionary Palmprint nodes with edges between these and other tax families to understand if they have similar vector/parasitic qualities\n",
    "\n",
    "\n",
    "#### Fisher's exact test \n",
    "- Fisher’s exact test is a statistical test used for testing the association between the two independent categorical variables\n",
    "- A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis\n",
    "\n",
    "Viral co-occurrence\n",
    "\n",
    "|              | (Virus_1, Host_1) | (Virus_1, Host_2) | Row total          |\n",
    "|--------------|-------------------|-------------------|--------------------|\n",
    "| T. Gondi     | a                 | b                 | a + b              |\n",
    "| Not T. Gondi | c                 | d                 | c + d              |\n",
    "| Column Total | a + c             | b + d             | a + b + c + d (=n) |\n",
    "\n",
    "Host Co-occurrence\n",
    "\n",
    "|              | (Virus_1, Host_1) | (Virus_2, Host_1) | Row total          |\n",
    "|--------------|-------------------|-------------------|--------------------|\n",
    "| T. Gondi     | a                 | b                 | a + b              |\n",
    "| Not T. Gondi | c                 | d                 | c + d              |\n",
    "| Column Total | a + c             | b + d             | a + b + c + d (=n) |\n",
    "\n",
    "\n",
    "#### Co-occurrence Triangles\n",
    "- Viral co-occurrence relates taxons by associating a common virus found in two different taxon families\n",
    "- Host Co-occurrence relates viruses by associating a common host to two different sOTU\n",
    "- Viral co-ocurrence across hosts shows indication of zoonotic potential, either through parasites or other viral vectors and causal interactions\n",
    "- Co-occurrence edges form triangles in the network. These triangles can be used in clustering algorithms, i.e. [Local Clustering Coeffecient](https://neo4j.com/docs/graph-data-science/current/algorithms/local-clustering-coefficient/) which describes the likelihood that the neighbours of node $n$ are also connected.\n",
    "- To compute $C_n$ we use the number of triangles a node is a part of $T_n$, and the degree of the node $d_n$. The formula to compute the local clustering coefficient is as follows:\n",
    "    $\n",
    "    {\\displaystyle\n",
    "    C_n = \\frac{2 T_n}{d_n(d_n - 1)}\n",
    "    }\n",
    "    $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Notebook config\n",
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "%load_ext dotenv\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "os.environ['R_HOME'] = '/Library/Frameworks/R.framework/Resources'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import matplotlib.pyplot as plt\n",
    "import graphistry\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "from datasources.neo4j import gds\n",
    "from queries import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphistry.register(\n",
    "    api=3,\n",
    "    username=os.getenv('GRAPHISTRY_USERNAME'),\n",
    "    password=os.getenv('GRAPHISTRY_PASSWORD'),\n",
    ")\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "base_data_path = './tgav_data/'\n",
    "toxo_data_path = base_data_path + 'toxo/'\n",
    "neo4j_data_path = base_data_path + 'neo4j/'\n",
    "graphistry_data_path = base_data_path + 'graphistry/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse SRA csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/wsxpm_412lgcfm03dqd31qmh0000gn/T/ipykernel_4247/687670111.py:3: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(toxo_data_path + 'toxo_SraRunInfo.csv')\n",
      "/var/folders/vl/wsxpm_412lgcfm03dqd31qmh0000gn/T/ipykernel_4247/687670111.py:12: DtypeWarning: Columns (25,26,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sra_union_metadata = pd.read_csv(toxo_data_path + 'tg_set_all_metadata_additional.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32473, 33)\n",
      "Index(['Run', 'biosample', 'bioproject', 'sample_acc', 'experiment',\n",
      "       'sra_study', 'organism', 'releasedate', 'loaddate', 'consent',\n",
      "       'librarysource', 'assay_type', 'librarylayout', 'libraryselection',\n",
      "       'platform', 'avgspotlen', 'insertsize', 'mbases', 'mbytes',\n",
      "       'library_name', 'sample_name', 'center_name',\n",
      "       'geo_loc_name_country_calc', 'geo_loc_name_country_continent_calc',\n",
      "       'geo_loc_name_sam', 'age', 'sex_val', 'temp_val', 'temp_units',\n",
      "       'age_val', 'age_units', 'age_seconds', 'TaxID'],\n",
      "      dtype='object')\n",
      "(845, 4)\n",
      "Index(['Run', 'TaxID_x', 'TaxID_y', 'TaxID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def get_toxo_dfs():\n",
    "    # Get RunID, TaxID pairs from original datasets\n",
    "    df1 = pd.read_csv(toxo_data_path + 'toxo_SraRunInfo.csv')\n",
    "    df2 = pd.read_csv(toxo_data_path + 'txid5810_SraRunInfo.csv')\n",
    "    df3 = pd.read_csv(toxo_data_path + 'txid5810_statbigquery.csv')\n",
    "    df3 = df3.rename(columns={'tax_id': 'TaxID', 'acc': 'Run'})\n",
    "    sra_union = pd.concat([df1[['Run', 'TaxID']], df2[['Run', 'TaxID']], df3[['Run', 'TaxID']]], axis=0)\n",
    "    sra_union = sra_union.drop_duplicates(subset=['Run'])\n",
    "    sra_union = sra_union.astype({\"Run\": str, \"TaxID\": int})\n",
    "\n",
    "    # Get additional biosample metadata (missing TaxId)\n",
    "    sra_union_metadata = pd.read_csv(toxo_data_path + 'tg_set_all_metadata_additional.csv')\n",
    "    sra_union_metadata = sra_union_metadata.rename(columns={'acc': 'Run'})\n",
    "    sra_union = sra_union_metadata.merge(\n",
    "        sra_union,\n",
    "        left_on='Run',\n",
    "        right_on='Run',\n",
    "        how='left',\n",
    "    ).drop_duplicates(subset=['Run'])\n",
    "\n",
    "    # Get intersection of original datasets\n",
    "    sra_intersection = df1[['Run', 'TaxID']].merge(\n",
    "        df2[['Run', 'TaxID']],\n",
    "        left_on='Run',\n",
    "        right_on='Run',\n",
    "        how='left',\n",
    "    ).dropna()\n",
    "    sra_intersection = sra_intersection.merge(\n",
    "        df3[['Run', 'TaxID']],\n",
    "        left_on='Run',\n",
    "        right_on='Run',\n",
    "        how='left',\n",
    "    ).dropna()\n",
    "    sra_intersection = sra_intersection.astype({\"Run\": str, \"TaxID\": int, \"TaxID_x\": int, \"TaxID_y\": int })\n",
    "\n",
    "    return sra_union, sra_intersection\n",
    "\n",
    "\n",
    "sra_union, sra_intersection = get_toxo_dfs()\n",
    "\n",
    "print(sra_union.shape)\n",
    "print(sra_union.columns)\n",
    "\n",
    "print(sra_intersection.shape)\n",
    "print(sra_intersection.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4j Query definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sra_exact_collections = \"\"\"\n",
    "    MATCH (a:Palmprint)<-[b:HAS_PALMPRINT]-(c:SRA)\n",
    "        -[d:HAS_HOST]->(e:Taxon)\n",
    "    WHERE e.taxId = '5810' \n",
    "    OR  (e)-[:HAS_PARENT*]->(:Taxon {taxId: '5810'})\n",
    "    RETURN COLLECT(DISTINCT c.runId) as run_ids, \n",
    "        COLLECT(DISTINCT a.palmId) as palm_ids, \n",
    "        COLLECT(DISTINCT e.taxId) as tax_ids\n",
    "\"\"\"\n",
    "\n",
    "query_sra_union_collections = \"\"\"\n",
    "    MATCH (a:Palmprint)<-[b:HAS_PALMPRINT]-(c:SRA)\n",
    "        -[d:HAS_HOST]->(e:Taxon)\n",
    "    WHERE c.runId in $run_ids\n",
    "    AND NOT (e)-[:HAS_PARENT*]->(:Taxon {taxId: '12908'})\n",
    "    RETURN COLLECT(DISTINCT c.runId) as run_ids, \n",
    "        COLLECT(DISTINCT a.palmId) as palm_ids, \n",
    "        COLLECT(DISTINCT e.taxId) as tax_ids\n",
    "\"\"\"\n",
    "\n",
    "query_sra_intersection_collections = \"\"\"\n",
    "    MATCH (a:Palmprint)<-[b:HAS_PALMPRINT]-(c:SRA)\n",
    "        -[d:HAS_HOST]->(e:Taxon)\n",
    "    WHERE c.runId in $intersection_ids\n",
    "    AND NOT (e)-[:HAS_PARENT*]->(:Taxon {taxId: '12908'})\n",
    "    RETURN COLLECT(DISTINCT c.runId) as run_ids, \n",
    "        COLLECT(DISTINCT a.palmId) as palm_ids, \n",
    "        COLLECT(DISTINCT e.taxId) as tax_ids\n",
    "\"\"\"\n",
    "\n",
    "query_sotus = \"\"\"\n",
    "    MATCH (n:SOTU)<-[r:HAS_SOTU*0..1]-(p:Palmprint)\n",
    "    WHERE n.palmId in $palm_ids OR p.palmId in $palm_ids\n",
    "    RETURN\n",
    "        id(n) as nodeId,\n",
    "        n.palmId as appId,\n",
    "        n.palmId as palmId,\n",
    "        labels(n) as labels,\n",
    "        n.centroid as centroid,\n",
    "        CASE WHEN n.palmId in ['u658323', 'u380516'] THEN True ELSE False END AS isRubyOrCougar,\n",
    "        CASE WHEN n.palmId in $intersection_ids THEN True ELSE False END AS datasetIntersection,\n",
    "        count(r) as numPalmprints\n",
    "\"\"\"\n",
    "\n",
    "query_taxons = \"\"\"\n",
    "    MATCH (n:Taxon)\n",
    "    WHERE n.taxId in $tax_ids\n",
    "    RETURN\n",
    "        id(n) as nodeId,\n",
    "        n.taxId as appId,\n",
    "        n.taxId as taxId,\n",
    "        labels(n) as labels,\n",
    "        n.rank as rank,\n",
    "        n.taxFamily as taxFamily,\n",
    "        CASE WHEN n.taxId in $intersection_ids THEN True ELSE False END AS datasetIntersection\n",
    "\"\"\"\n",
    "\n",
    "query_taxons_family = \"\"\"\n",
    "    CALL {\n",
    "        MATCH (t:Taxon)-[:HAS_PARENT*]->(n:Taxon)\n",
    "        WHERE t.taxId in $tax_ids\n",
    "        AND n.rank = 'family'\n",
    "        RETURN n, t\n",
    "        UNION\n",
    "        MATCH (n:Taxon)\n",
    "        WHERE n.taxId in $tax_ids\n",
    "        AND n.rank = 'family'\n",
    "        RETURN n, null as t\n",
    "    }\n",
    "    WITH n, t\n",
    "    RETURN\n",
    "        id(n) as nodeId,\n",
    "        n.taxId as appId,\n",
    "        n.taxId as taxId,\n",
    "        labels(n) as labels,\n",
    "        n.rank as rank,\n",
    "        n.taxFamily as taxFamily,\n",
    "        CASE WHEN (n.taxId in $intersection_ids OR t.taxId in $intersection_ids)\n",
    "            THEN True ELSE False END AS datasetIntersection\n",
    "\"\"\"\n",
    "\n",
    "query_direct_has_host_edges = '''\n",
    "    CALL {\n",
    "        MATCH (p:SOTU)<-[:HAS_SOTU]-(:Palmprint)<-[r:HAS_PALMPRINT]-(s:SRA)\n",
    "            -[:HAS_HOST]->()-[:HAS_PARENT*0..]->(t:Taxon {rank: 'family'})\n",
    "        WHERE s.runId in $run_ids\n",
    "        AND p.palmId in $sotus\n",
    "        AND t.taxId in $family_tax_ids\n",
    "        AND not (t)-[:HAS_PARENT*]->(:Taxon {taxId: '12908'})\n",
    "        RETURN p, t, r, s\n",
    "        UNION\n",
    "        MATCH (p:SOTU)<-[r:HAS_PALMPRINT]-(s:SRA)\n",
    "            -[:HAS_HOST]->()-[:HAS_PARENT*0..]->(t:Taxon {rank: 'family'})\n",
    "        WHERE s.runId in $run_ids\n",
    "        AND p.palmId in $sotus\n",
    "        AND t.taxId in $family_tax_ids\n",
    "        AND not (t)-[:HAS_PARENT*]->(:Taxon {taxId: '12908'})\n",
    "        RETURN p, t, r, s\n",
    "    }\n",
    "    WITH p, t, r, s \n",
    "    RETURN\n",
    "        id(p) as sourceNodeId,\n",
    "        p.palmId as sourceAppId,\n",
    "        id(t) as targetNodeId,\n",
    "        t.taxId as targetAppId,\n",
    "        'HAS_HOST' as relationshipType,\n",
    "        count(*) AS directAssociations,\n",
    "        count(*) AS count,\n",
    "        avg(r.percentIdentity) as avgPercentIdentity,\n",
    "        avg(r.percentIdentity) as weight,\n",
    "        CASE WHEN s.runId in $intersection_ids THEN True ELSE False END AS datasetIntersection,\n",
    "        'True' as isDirect\n",
    "'''\n",
    "\n",
    "query_direct_has_host_edges_stash = '''\n",
    "        MATCH (p:SOTU)<-[:HAS_SOTU]-(:Palmprint)<-[r:HAS_PALMPRINT]-(s:SRA)\n",
    "            -[:HAS_HOST]->()-[:HAS_PARENT*0..]->(t:Taxon {rank: 'family'})\n",
    "        WHERE s.runId in $run_ids\n",
    "        AND p.palmId in $sotus\n",
    "        AND t.taxId in $family_tax_ids\n",
    "        AND not (t)-[:HAS_PARENT*]->(:Taxon {taxId: '12908'})\n",
    "    RETURN\n",
    "        id(p) as sourceNodeId,\n",
    "        p.palmId as sourceAppId,\n",
    "        id(t) as targetNodeId,\n",
    "        t.taxId as targetAppId,\n",
    "        'HAS_HOST' as relationshipType,\n",
    "        count(*) AS directAssociations,\n",
    "        count(*) AS count,\n",
    "        avg(r.percentIdentity) as avgPercentIdentity,\n",
    "        avg(r.percentIdentity) as weight,\n",
    "        CASE WHEN s.runId in $intersection_ids THEN True ELSE False END AS datasetIntersection,\n",
    "        'True' as isDirect\n",
    "'''\n",
    "\n",
    "query_indirect_has_host_edges = '''\n",
    "    CALL {\n",
    "        MATCH (p:SOTU)<-[:HAS_SOTU]-(:Palmprint)<-[r:HAS_PALMPRINT]-(s:SRA)\n",
    "            -[:HAS_HOST]->()-[:HAS_PARENT*0..]->(t:Taxon {rank: 'family'})\n",
    "        WHERE NOT s.runId IN $run_ids\n",
    "        AND p.palmId IN $sotus\n",
    "        AND t.taxId IN $family_tax_ids\n",
    "        RETURN p, t, r, s\n",
    "        UNION\n",
    "        MATCH (p:SOTU)<-[r:HAS_PALMPRINT]-(s:SRA)\n",
    "            -[:HAS_HOST]->()-[:HAS_PARENT*0..]->(t:Taxon {rank: 'family'})\n",
    "        WHERE NOT s.runId IN $run_ids\n",
    "        AND p.palmId IN $sotus\n",
    "        AND t.taxId IN $family_tax_ids\n",
    "        RETURN p, t, r, s\n",
    "    }\n",
    "    WITH p, t, r, s\n",
    "    RETURN\n",
    "        id(p) as sourceNodeId,\n",
    "        p.palmId as sourceAppId,\n",
    "        id(t) as targetNodeId,\n",
    "        t.taxId as targetAppId,\n",
    "        'HAS_HOST_INDIRECT' as relationshipType,\n",
    "        count(*) AS indirectAssociations,\n",
    "        count(*) AS count,\n",
    "        avg(r.percentIdentity) as avgPercentIdentity,\n",
    "        avg(r.percentIdentity) as weight,\n",
    "        CASE WHEN s.runId in $intersection_ids THEN True ELSE False END AS datasetIntersection,\n",
    "        'False' as isDirect\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Neo4j dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: issue with partial cached dfs causing some queries to be empty/missing, likely a parsing issue.\n",
    "# workaround: deleting all cached csvs and refetch all after making updates  \n",
    "\n",
    "run_ids_union = list(sra_union.Run.unique())\n",
    "run_ids_intersection = list(sra_intersection.Run.unique())\n",
    "\n",
    "def _log_df(df):\n",
    "    namespace = globals()\n",
    "    var_name = [name for name in namespace if namespace[name] is df]\n",
    "    print(var_name, df.shape)\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "def fetch_cached_df(query, params, filename, use_cache=True, log=False):\n",
    "    if os.path.exists(neo4j_data_path + filename) and use_cache:\n",
    "        df = pd.read_csv(neo4j_data_path + filename)\n",
    "        df = utils.deserialize_df(df)\n",
    "    else:\n",
    "        df = gds.run_cypher(query, params=params)\n",
    "        df.to_csv(neo4j_data_path + filename, index=False)\n",
    "    if log:\n",
    "        _log_df(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_neo4j_data():\n",
    "    exact_collections = fetch_cached_df(\n",
    "        query_sra_exact_collections,\n",
    "        {},\n",
    "        'sra_exact_collections.csv'\n",
    "    )\n",
    "    union_collections = fetch_cached_df(\n",
    "        query_sra_union_collections,\n",
    "        {\n",
    "            'run_ids': list(run_ids_union),\n",
    "            'intersection_ids': list(run_ids_intersection),\n",
    "        },\n",
    "        'sra_union_collections.csv'\n",
    "    )\n",
    "    intersection_collections = fetch_cached_df(\n",
    "        query_sra_intersection_collections,\n",
    "        {\n",
    "            'run_ids': list(run_ids_union),\n",
    "            'intersection_ids': list(run_ids_intersection),\n",
    "        },\n",
    "        'sra_intersection_collections.csv'\n",
    "    )\n",
    "    sotu_nodes = fetch_cached_df(\n",
    "        query_sotus,\n",
    "        {\n",
    "            'palm_ids': list(union_collections['palm_ids'][0]),\n",
    "            'intersection_ids': list(intersection_collections['palm_ids'][0]),\n",
    "        },\n",
    "        'sotu_nodes.csv'\n",
    "    )\n",
    "    taxon_nodes = fetch_cached_df(\n",
    "        query_taxons,\n",
    "        {\n",
    "            'tax_ids': list(union_collections['tax_ids'][0]),\n",
    "            'intersection_ids': list(intersection_collections['tax_ids'][0]),\n",
    "        },\n",
    "        'taxon_nodes.csv'\n",
    "    )\n",
    "    taxon_family_nodes = fetch_cached_df(\n",
    "        query_taxons_family,\n",
    "        {\n",
    "            'tax_ids': list(union_collections['tax_ids'][0]),\n",
    "            'intersection_ids': list(intersection_collections['tax_ids'][0]),\n",
    "        },\n",
    "        'taxons_family_nodes.csv'\n",
    "    )\n",
    "    # Some taxons are missing family information and have no ancestors with family information\n",
    "    taxon_nodes_missing_family = taxon_nodes[taxon_nodes['taxFamily'].isna()]\n",
    "    has_host_edges = fetch_cached_df(\n",
    "        query_direct_has_host_edges,\n",
    "        {\n",
    "            'run_ids': list(union_collections['run_ids'][0]),\n",
    "            'sotus': sotu_nodes['appId'].tolist(),\n",
    "            'family_tax_ids': taxon_family_nodes['appId'].tolist(),\n",
    "            'intersection_ids': list(intersection_collections['run_ids'][0]),\n",
    "        },\n",
    "        'direct_has_host_edges.csv'\n",
    "    )\n",
    "    indirect_has_host_edges = fetch_cached_df(\n",
    "        query_indirect_has_host_edges,\n",
    "        {\n",
    "            'run_ids': list(union_collections['run_ids'][0]),\n",
    "            'sotus': sotu_nodes['appId'].tolist(),\n",
    "            'family_tax_ids': taxon_family_nodes['appId'].tolist(),\n",
    "            'intersection_ids': list(intersection_collections['run_ids'][0]),\n",
    "        },\n",
    "        'indirect_has_host_edges.csv'\n",
    "    )\n",
    "    return {\n",
    "        'exact_collections': exact_collections,\n",
    "        'union_collections': union_collections,\n",
    "        'intersection_collections': intersection_collections,\n",
    "        'sotu_nodes': sotu_nodes,\n",
    "        'taxon_nodes': taxon_nodes,\n",
    "        'taxon_family_nodes': taxon_family_nodes,\n",
    "        'taxon_nodes_missing_family': taxon_nodes_missing_family,\n",
    "        'has_host_edges': has_host_edges,\n",
    "        'indirect_has_host_edges': indirect_has_host_edges,\n",
    "    }\n",
    "\n",
    "neo4j_data = get_neo4j_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community detection and node centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_gds_projection(neo4j_data):\n",
    "    graph_name = 'tgav'\n",
    "    nodes = pd.concat([\n",
    "        neo4j_data['sotu_nodes'][['nodeId', 'labels']],\n",
    "        neo4j_data['taxon_family_nodes'][['nodeId', 'labels']],\n",
    "        neo4j_data['taxon_nodes_missing_family'][['nodeId', 'labels']],\n",
    "    ])\n",
    "    relationships = pd.concat([\n",
    "        neo4j_data['has_host_edges'][['sourceNodeId', 'targetNodeId',  'relationshipType', 'weight']],\n",
    "    ])\n",
    "\n",
    "    if gds.graph.exists(graph_name)['exists']:\n",
    "        gds.graph.drop(gds.graph.get(graph_name))\n",
    "\n",
    "    G = gds.alpha.graph.construct(\n",
    "        graph_name=graph_name,\n",
    "        nodes=nodes,\n",
    "        relationships=relationships,\n",
    "        concurrency=4,\n",
    "        undirected_relationship_types=['HAS_HOST'],\n",
    "    )\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_community_analysis(G):\n",
    "  communities = gds.labelPropagation.stream(\n",
    "    G,\n",
    "    nodeLabels=['Taxon', 'Palmprint'],\n",
    "    relationshipWeightProperty='weight',\n",
    "    maxIterations=30,\n",
    "  )\n",
    "  unique_communities = communities.communityId.unique()\n",
    "  community_counter = collections.Counter(communities.communityId)\n",
    "  print(len(unique_communities))\n",
    "  print(community_counter.most_common(10))\n",
    "\n",
    "  page_ranks = gds.pageRank.stream(\n",
    "      G,\n",
    "    relationshipWeightProperty='weight',\n",
    "    maxIterations=100,\n",
    "  )\n",
    "  page_ranks = page_ranks.rename(columns={'score': 'pageRank'})\n",
    "  page_ranks['pageRank'] = page_ranks['pageRank'].round(0)\n",
    "\n",
    "  page_ranks_sotu = gds.pageRank.stream(\n",
    "    G,\n",
    "    nodeLabels=['Palmprint'],\n",
    "    relationshipWeightProperty='weight',\n",
    "    maxIterations=100,\n",
    "  )\n",
    "  page_ranks_sotu = page_ranks_sotu.rename(columns={'score': 'pageRankSotu'})\n",
    "  page_ranks_sotu['pageRankSotu'] = page_ranks_sotu['pageRankSotu'].round(0)\n",
    "\n",
    "  celf = gds.beta.influenceMaximization.celf.stream(\n",
    "      G,\n",
    "      seedSetSize=25,\n",
    "  )\n",
    "  celf = celf.rename(columns={'spread': 'celf'})\n",
    "  celf['celf'] = celf['celf'].round(0)\n",
    "  G.drop()\n",
    "  return communities, page_ranks, page_ranks_sotu, celf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pvalues: Fisher's Exact + Chi-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = importr('stats')\n",
    "\n",
    "def get_contingency_tables(grouped_df, co_assoc_on='targetAppId'):\n",
    "    def get_empty_contingency_table():\n",
    "        return collections.defaultdict(lambda: [0, 0])\n",
    "    \n",
    "    contingency_tables = collections.defaultdict(get_empty_contingency_table)\n",
    "\n",
    "    for group_keys, df_group in grouped_df:\n",
    "        group_name = group_keys[0]\n",
    "        table_row = int(group_keys[1] == 'True' or group_keys[1] == True)\n",
    "        for _, row in df_group.iterrows():\n",
    "            contingency_tables[group_name][row[co_assoc_on]][table_row] += row['count']\n",
    "    return contingency_tables\n",
    "\n",
    "\n",
    "def get_pvals_from_contingency_table(contingency_table, row):\n",
    "    try:\n",
    "        args = {\n",
    "            'B': 1e5, # decrease number of simulations (speeds up calculation)\n",
    "            'simulate.p.value': True, # (improves memory usage)   \n",
    "            # 'workspace': 1e+9,\n",
    "        }\n",
    "        if len(contingency_table) == 2:\n",
    "            args['alternative'] = \"two.sided\"\n",
    "        fisher_res = stats.fisher_test(contingency_table, **args)\n",
    "        row['fisher'] = fisher_res[0][0]\n",
    "    except Exception as e:\n",
    "        row['fisher'] = -1.0\n",
    "    try:\n",
    "        chi2_res = chi2_contingency(contingency_table)\n",
    "        row['chi2'] = chi2_res.pvalue\n",
    "    except Exception as e:\n",
    "        row['chi2'] = -1.0\n",
    "    return row\n",
    "\n",
    "def get_binary_pvalues(contingency_tables):\n",
    "    pval_rows = []\n",
    "    for group_name, table_dict in contingency_tables.items():\n",
    "        all_keys = set(table_dict.keys())\n",
    "\n",
    "        for key, values in table_dict.items():\n",
    "            table_dict_complement = {\n",
    "                k: table_dict[k] \n",
    "                for k in all_keys - set([key])\n",
    "            }\n",
    "            values_complement =  [\n",
    "                sum([val[0] for val in table_dict_complement.values()]),\n",
    "                sum([val[1] for val in table_dict_complement.values()]),\n",
    "            ]\n",
    "            contingency_table = np.array([\n",
    "                values,\n",
    "                values_complement,\n",
    "            ])\n",
    "            row = {\n",
    "                'sourceAppId': group_name,\n",
    "                'targetAppId': key,\n",
    "                'fisher': 0.0,\n",
    "                'chi2': 0.0,\n",
    "            }\n",
    "            if len(contingency_table) == 1:\n",
    "                row['fisher'] = -1.0\n",
    "                row['chi2'] = -1.0\n",
    "            \n",
    "            if len(contingency_table) > 1:\n",
    "                row = get_pvals_from_contingency_table(contingency_table, row)\n",
    "            pval_rows.append(row)\n",
    "            if len(pval_rows) % 10000 == 0:\n",
    "                print(len(pval_rows))\n",
    "        \n",
    "    pval_df = pd.DataFrame(pval_rows)\n",
    "    return pval_df\n",
    "\n",
    "\n",
    "def get_multi_pvalues(contingency_tables):\n",
    "    pval_rows = []\n",
    "    for group_name, table_dict in contingency_tables.items():\n",
    "        contingency_table = np.array(list(table_dict.values()))\n",
    "        row = {\n",
    "            'appId': group_name,\n",
    "            'fisher': 0.0,\n",
    "            'chi2': 0.0,\n",
    "        }\n",
    "        if len(contingency_table) == 1:\n",
    "            row['fisher'] = -1.0\n",
    "            row['chi2'] = -1.0\n",
    "        \n",
    "        if len(contingency_table) > 1:\n",
    "            row = get_pvals_from_contingency_table(contingency_table, row)\n",
    "            \n",
    "        pval_rows.append(row)\n",
    "        if len(pval_rows) % 500 == 0:\n",
    "            print(len(pval_rows))\n",
    "\n",
    "    pval_df = pd.DataFrame(pval_rows)\n",
    "    return pval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pvals of 0 correspond to palmprints with only a single host\n",
    "# pvals of 1 correspond to palmprints with no overlap in co-association\n",
    "\n",
    "# contingency table for host co-associations is too large to compute fisher exact test, use chi-squared instead\n",
    "\n",
    "# groups: palmId\n",
    "# rows: isDirect (True/False)\n",
    "# cols: taxId\n",
    "\n",
    "\n",
    "def run_pval_analysis(neo4j_data):\n",
    "    grouped_sotu_df = pd.concat([\n",
    "        neo4j_data['has_host_edges'],\n",
    "        neo4j_data['indirect_has_host_edges'],\n",
    "    ]).groupby(['sourceAppId', 'isDirect'])\n",
    "\n",
    "    co_assoc_on_sotu = 'targetAppId'\n",
    "    contingency_tables = get_contingency_tables(grouped_sotu_df, co_assoc_on_sotu)\n",
    "\n",
    "    binary_pval_df = get_binary_pvalues(contingency_tables)\n",
    "    binary_pval_df['binaryFisher'] = binary_pval_df['fisher'].round(1)\n",
    "    binary_pval_df['binaryChi2'] = binary_pval_df['chi2'].round(1)\n",
    "\n",
    "    multi_pval_df = get_multi_pvalues(contingency_tables)\n",
    "    multi_pval_df['multiFisher'] = multi_pval_df['fisher'].round(1)\n",
    "    multi_pval_df['multiChi2'] = multi_pval_df['chi2'].round(1)\n",
    "\n",
    "    # grouped_host_target = pd.concat([\n",
    "    #     neo4j_data['has_host_edges'],\n",
    "    #     neo4j_data['indirect_has_host_edges'],\n",
    "    # ]).groupby(['targetAppId', 'isDirect'])\n",
    "    \n",
    "    return binary_pval_df, multi_pval_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31926, 11)\n",
      "2781\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "print(neo4j_data['indirect_has_host_edges'].shape)\n",
    "\n",
    "print(neo4j_data['indirect_has_host_edges'].sourceNodeId.nunique())\n",
    "print(neo4j_data['indirect_has_host_edges'].targetNodeId.nunique())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphistry visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node and relationship dataframes with full information\n",
    "# TODO: refactor args to lists for nodes, edges \n",
    "def get_graphistry_df(\n",
    "        neo4j_data, communities, page_ranks, \n",
    "        page_ranks_sotu, celf, binary_pvals, multi_pvals\n",
    "    ):\n",
    "    neo4j_data['sotu_nodes']['displayLabel'] = neo4j_data['sotu_nodes']['appId']\n",
    "    neo4j_data['taxon_family_nodes']['displayLabel'] = neo4j_data['taxon_family_nodes']['taxFamily']\n",
    "    neo4j_data['taxon_nodes_missing_family']['displayLabel'] = 'Unknown'\n",
    "\n",
    "    nodes = pd.concat([\n",
    "        neo4j_data['sotu_nodes'],\n",
    "        neo4j_data['taxon_family_nodes'],\n",
    "        neo4j_data['taxon_nodes_missing_family'],\n",
    "    ])\n",
    "    nodes = nodes.merge(\n",
    "        page_ranks,\n",
    "        left_on='nodeId',\n",
    "        right_on='nodeId',\n",
    "        how='left',\n",
    "    )\n",
    "    nodes = nodes.merge(\n",
    "        page_ranks_sotu,\n",
    "        left_on='nodeId',\n",
    "        right_on='nodeId',\n",
    "        how='left',\n",
    "    )\n",
    "    nodes = nodes.merge(\n",
    "        communities,\n",
    "        left_on='nodeId',\n",
    "        right_on='nodeId',\n",
    "        how='left',\n",
    "    )\n",
    "    nodes = nodes.merge(\n",
    "        celf,\n",
    "        left_on='nodeId',\n",
    "        right_on='nodeId',\n",
    "        how='left',\n",
    "    )\n",
    "    nodes = nodes.merge(\n",
    "        multi_pvals,\n",
    "        left_on='appId',\n",
    "        right_on='appId',\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "    nodes['type'] = nodes['labels']\n",
    "\n",
    "    nodes = nodes[[\n",
    "        'appId', 'labels', 'type', \n",
    "        'centroid', 'rank', 'communityId',\n",
    "        'taxFamily', 'isRubyOrCougar', \n",
    "        'displayLabel', 'datasetIntersection',\n",
    "        'pageRank', 'pageRankSotu', 'celf',\n",
    "        'multiFisher', 'multiChi2',\n",
    "    ]].astype(str)\n",
    "\n",
    "    relationships = pd.concat([\n",
    "        neo4j_data['has_host_edges'],\n",
    "    ])\n",
    "    binary_pvals['targetAppId'] = binary_pvals['targetAppId'].astype(str)\n",
    "    binary_pvals['sourceAppId'] = binary_pvals['sourceAppId'].astype(str)\n",
    "    relationships['targetAppId'] = relationships['targetAppId'].astype(str)\n",
    "    relationships['sourceAppId'] = relationships['sourceAppId'].astype(str)\n",
    "    relationships = relationships.merge(\n",
    "        binary_pvals,\n",
    "        on=['sourceAppId', 'targetAppId'],\n",
    "        how='left',\n",
    "    )\n",
    "    relationships = relationships.rename(columns={'sourceAppId_x': 'sourceAppId', 'targetAppId_x': 'targetAppId'})\n",
    "    relationships = relationships[[\n",
    "        'sourceAppId', 'targetAppId', 'relationshipType', \n",
    "        'weight', 'datasetIntersection',\n",
    "        'binaryFisher', 'binaryChi2', \n",
    "    ]].astype(str)\n",
    "\n",
    "    # Encode communityId to use default color pallette\n",
    "    nodes['communityId'] = nodes['communityId'].astype('int32')\n",
    "    labels = nodes['communityId'].unique()\n",
    "    mapping = {label: i for i, label in enumerate(labels)}\n",
    "    nodes['communityId'] =  nodes['communityId'].replace(mapping)\n",
    "    nodes['communityColorCodes'] = nodes['communityId'].mod(12)\n",
    "\n",
    "    return nodes, relationships\n",
    "\n",
    "\n",
    "\n",
    "def load_or_create_graphistry_df(node_filename, relationship_filename, use_cache=False):\n",
    "    if use_cache and os.path.exists(graphistry_data_path + node_filename) \\\n",
    "            and os.path.exists(graphistry_data_path + relationship_filename):\n",
    "        nodes = pd.read_csv(graphistry_data_path + node_filename)\n",
    "        edges = pd.read_csv(graphistry_data_path + relationship_filename)\n",
    "    else:\n",
    "        neo4j_data = get_neo4j_data()\n",
    "        G = construct_gds_projection(neo4j_data)\n",
    "        communities, page_ranks, page_ranks_sotu, celf = run_community_analysis(G)\n",
    "        binary_pvals, multi_pvals = run_pval_analysis(neo4j_data)\n",
    "        nodes, edges = get_graphistry_df(\n",
    "            neo4j_data, communities, page_ranks, page_ranks_sotu, celf, binary_pvals, multi_pvals\n",
    "        )\n",
    "        nodes.to_csv(graphistry_data_path + node_filename, index=False)\n",
    "        edges.to_csv(graphistry_data_path + relationship_filename, index=False)\n",
    "    return nodes, edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "[(11156590, 1862), (8763616, 384), (8764798, 312), (8760548, 194), (8759540, 148), (8764001, 136), (8758893, 79), (8763875, 77), (8761256, 75), (8759772, 60)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CELF: 100%|██████████| 100.0/100 [00:01<00:00, 86.51%/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in (function (x, y = NULL, workspace = 2e+05, hybrid = FALSE, hybridPars = c(expect = 5,  : \n",
      "  need 2 or more non-zero column marginals\n",
      "R[write to console]: Error in (function (x, y = NULL, workspace = 2e+05, hybrid = FALSE, hybridPars = c(expect = 5,  : \n",
      "  need 2 or more non-zero column marginals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2500\n",
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in (function (x, y = NULL, workspace = 2e+05, hybrid = FALSE, hybridPars = c(expect = 5,  : \n",
      "  need 2 or more non-zero column marginals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/wsxpm_412lgcfm03dqd31qmh0000gn/T/ipykernel_4247/2169088935.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neo4j_data['taxon_nodes_missing_family']['displayLabel'] = 'Unknown'\n"
     ]
    }
   ],
   "source": [
    "nodes, relationships = load_or_create_graphistry_df('nodes.csv', 'edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['appId', 'labels', 'type', 'centroid', 'rank', 'communityId',\n",
      "       'taxFamily', 'isRubyOrCougar', 'displayLabel', 'datasetIntersection',\n",
      "       'pageRank', 'pageRankSotu', 'celf', 'multiFisher', 'multiChi2',\n",
      "       'communityColorCodes'],\n",
      "      dtype='object')\n",
      "Index(['sourceAppId', 'targetAppId', 'relationshipType', 'weight',\n",
      "       'datasetIntersection', 'binaryFisher', 'binaryChi2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(nodes.columns)\n",
    "print(relationships.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <iframe id=\"3c613523-94cc-4420-a9bc-4fa2cd8bba5f\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=7f12781e715449c3adb0b8f328e6487b&type=arrow&viztoken=ccff249e-af32-4f33-b996-2108d771e0ea&usertag=4ba963ab-pygraphistry-0.29.2&splashAfter=1689827567&info=True&play=2000&menu=True&showArrows=True&edgeOpacity=0.25&pointOpacity=1.0&linLog=True&compactLayout=True&strongGravity=True&dissuadeHubs=True&edgeInfluence=5&showLabelPropertiesOnHover=True&pointsOfInterestMax=15\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
       "                    \n",
       "            >\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#3c613523-94cc-4420-a9bc-4fa2cd8bba5f\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = graphistry.bind()\n",
    "\n",
    "g = g.bind(\n",
    "    source='sourceAppId',\n",
    "    destination='targetAppId',\n",
    ").edges(relationships)\n",
    "\n",
    "g = g.bind(node='appId', point_label='displayLabel').nodes(nodes)\n",
    "\n",
    "params = {\n",
    "        'play': 2000,\n",
    "        'menu': True, \n",
    "        'info': True,\n",
    "        'showArrows': True,\n",
    "        # 'pointSize': 2.0, \n",
    "        # 'edgeCurvature': 0.5,\n",
    "        'edgeOpacity': 0.25, \n",
    "        'pointOpacity': 1.0,\n",
    "        # 'lockedX': False, 'lockedY': False, 'lockedR': False,\n",
    "        'linLog': True, \n",
    "        'compactLayout': True,\n",
    "        'strongGravity': True,\n",
    "        'dissuadeHubs': True,\n",
    "        'edgeInfluence': 5,\n",
    "        # 'precisionVsSpeed': 0, 'gravity': 1.0, 'scalingRatio': 1.0,\n",
    "        # 'showLabels': True, 'showLabelOnHover': True,\n",
    "        # 'showPointsOfInterest': True, 'showPointsOfInterestLabel': True, \n",
    "        'showLabelPropertiesOnHover': True,\n",
    "        'pointsOfInterestMax': 15,\n",
    "      }\n",
    "\n",
    "g = g.settings(url_params=params)\n",
    "\n",
    "g = g.encode_point_color(\n",
    "    'communityColorCodes',\n",
    ")\n",
    "\n",
    "g.plot()\n",
    "\n",
    "# point:fisher IN (\"nan\", \"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\", \"0.8\", \"0.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play=2000&menu=True&info=True&showArrows=True&edgeOpacity=0.25&pointOpacity=1.0&linLog=True&compactLayout=True&strongGravity=True&dissuadeHubs=True&edgeInfluence=5&showLabelPropertiesOnHover=True&pointsOfInterestMax=15\n"
     ]
    }
   ],
   "source": [
    "print(urllib.parse.urlencode(params))\n",
    "# https://hub.graphistry.com/graph/graph.html?dataset=5aeb386c894148c28a19e3423ddb7f65&\n",
    "# https://hub.graphistry.com/graph/graph.html?dataset=5aeb386c894148c28a19e3423ddb7f65&play=2000&menu=True&info=True&showArrows=True&edgeOpacity=0.25&pointOpacity=1.0&linLog=True&compactLayout=True&strongGravity=True&dissuadeHubs=True&edgeInfluence=5&showLabelPropertiesOnHover=True&pointsOfInterestMax=15&splashAfter=false&session=8ad322bd6c3242dca620083ac8e0eb5f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misc notes\n",
    "\n",
    "- palmprint `u1023924` has fisher pvalue 0.3, degree out 6:\n",
    "    - 4479 (grass), 3803 (pea), 27065 (flower), 3481 (hemp), 4747 (orchid), 16714 (walnut)\n",
    "\n",
    "- check pvalue computation correct:\n",
    "\n",
    "- look into low pvalue viruses, con\n",
    "\n",
    "- look into categorizing taxons by descendents of viruses?\n",
    "    - add taxKingdom, etc.\n",
    "    - may be able to discern causal interaction: food, bacterial infection, \n",
    "\n",
    "- alternative plotting of grahp\n",
    "    - umap on pvalue to produce hypergeometric distribution (signature of virome)\n",
    "    - cluster on pvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install umap-learn \n",
    "# https://github.com/graphistry/pygraphistry/blob/master/demos/demos_databases_apis/umap_learn/umap_learn.ipynb\n",
    "import umap \n",
    "umap_options = {\n",
    "    'n_components': 2,\n",
    "    'metric': 'euclidean'\n",
    "}\n",
    "embedding = umap.UMAP(**umap_options).fit(df3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnalab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "448a416c49845ffbddc886562179757704d684dae284cc536cfa1eca10a7a7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
