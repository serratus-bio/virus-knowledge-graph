{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCBI STAT Host associations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fetch list of existing run_ids in sra_stat table in Serratus SQL DB\n",
    "1. Create BigQuery dataset and table with single existing run_ids columns\n",
    "1. Use complement of join on STAT table and existing run_ids to find all missing STAT rows\n",
    "1. Download missing rows to disk to limit API usage\n",
    "1. Use dask dataframe to compute additional/enriched values for new rows (groupby total kmers, percent, label)\n",
    "1. Write new STAT tax values to psql\n",
    "1. Write new edge values to neo4j using containerized ETL job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, configs, global helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from queries import serratus_queries, graph_queries\n",
    "from datasources import psql\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukepereira/anaconda3/envs/rnalab/lib/python3.11/site-packages/google/auth/_default.py:78: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "ProgressBar().register()\n",
    "\n",
    "# Authenticate GCP\n",
    "# !gcloud auth application-default login\n",
    "project_id = 'rnalab-393418'\n",
    "client = bigquery.Client(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_one(query, params={}):\n",
    "    conn = psql.get_serratus_connection()\n",
    "    cursor = conn.cursor()\n",
    "    resp = cursor.execute(query, params)\n",
    "    resp = cursor.fetchone()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return resp\n",
    "\n",
    "def fetch_count(query, params={}):\n",
    "    resp = fetch_one(query, params)\n",
    "    return int(resp[0])\n",
    "\n",
    "def fetch_all(query, params={}):\n",
    "    conn = psql.get_serratus_connection()\n",
    "    cursor = conn.cursor()\n",
    "    resp = cursor.execute(query, params)\n",
    "    resp = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return resp\n",
    "\n",
    "def get_write_connection():\n",
    "    return psycopg2.connect(\n",
    "        database=\"summary\",\n",
    "        host=\"serratus-aurora-20210406.cluster-ro-ccz9y6yshbls.us-east-1.rds.amazonaws.com\",\n",
    "        user=os.environ.get('SQL_WRITE_USER'),\n",
    "        password=os.environ.get('SQL_WRITE_PASSWORD'),\n",
    "        port=\"5432\")\n",
    "\n",
    "def get_max_row_id():\n",
    "    conn = psql.get_serratus_connection()\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "        SELECT max(CAST(row_id as Int)) FROM sra_stat;\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    out = cursor.fetchone()[0]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return int(out)\n",
    "\n",
    "def get_existing_stat_runs():\n",
    "    query = \"\"\"\n",
    "        SELECT distinct run \n",
    "        FROM public.sra_stat \n",
    "    \"\"\"\n",
    "    resp = fetch_all(query)\n",
    "    return resp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich stats data with labels and kmer_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kmer_perc(stats_data):\n",
    "    total_kmer = stats_data.groupby('run').agg({'kmer': 'sum'}).reset_index()\n",
    "    # assert stats_data.run.nunique() == total_kmer.shape[0]\n",
    "    total_kmer = total_kmer.rename(columns={'kmer': 'total_kmers'})\n",
    "\n",
    "    stats_data_totals = stats_data.merge(\n",
    "        total_kmer[['run', 'total_kmers']],\n",
    "        left_on='run',\n",
    "        right_on='run',\n",
    "    )\n",
    "    stats_data_totals['kmer_perc'] = (stats_data_totals['kmer'] / stats_data_totals['total_kmers']) * 100\n",
    "    stats_data_totals['kmer_perc'] = stats_data_totals['kmer_perc'].round(2)\n",
    "    # Note, existing table contains 15,552,449/85,551,530 (20%) that have kmer_perc == 0.0\n",
    "    return stats_data_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_tax_labels():\n",
    "    query = \"\"\"\n",
    "        SELECT * FROM public.sra_stat_group\n",
    "        ORDER BY taxid ASC\n",
    "    \"\"\"\n",
    "    return fetch_all(query)\n",
    "\n",
    "stats_tax_labels = get_stats_tax_labels()\n",
    "stats_tax_labels = pd.DataFrame(stats_tax_labels, columns=['taxid', 'tax_rank', 'tax_name', 'tax_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_stats_data(stats_data):\n",
    "    stats_data_totals = compute_kmer_perc(stats_data)\n",
    "    stats_data_totals_labels = stats_data_totals.merge(\n",
    "        stats_tax_labels[['taxid', 'tax_label']],\n",
    "        left_on='taxid',\n",
    "        right_on='taxid',\n",
    "        how='left',\n",
    "    )\n",
    "    return stats_data_totals_labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch all missing runs from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset rnalab-393418.stat_accessions\n"
     ]
    }
   ],
   "source": [
    "# Create BigQuery dataset and table\n",
    "dataset_id = \"{}.stat_accessions\".format(client.project)\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"US\"\n",
    "dataset = client.create_dataset(dataset, timeout=30)\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "\n",
    "tables = client.list_tables(project_id + \".stat_accessions\")\n",
    "for table in tables:\n",
    "    print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"acc\", \"STRING\", mode=\"REQUIRED\"),\n",
    "]\n",
    "table_id = project_id + \".stat_accessions.existing_accessions\"\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'existing_stat_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(existing_stat_runs, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mstat_tax_host.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'existing_stat_runs' is not defined"
     ]
    }
   ],
   "source": [
    "existing_stat_runs = get_existing_stat_runs()\n",
    "df = pd.DataFrame(existing_stat_runs, columns=['acc'])\n",
    "df.to_csv('stat_tax_host.csv', index=False)\n",
    "# Manually uploade csv to google cloud storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12487486 rows.\n"
     ]
    }
   ],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"acc\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = \"gs://rnalab/stat_tax_host.csv\"\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  \n",
    "load_job.result()  \n",
    "destination_table = client.get_table(table_id) \n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT acc, tax_id, rank, name, total_count\n",
    "    FROM nih-sra-datastore.sra_tax_analysis_tool.tax_analysis\n",
    "    WHERE rank = 'order'\n",
    "    AND total_count >= 100\n",
    "    AND acc NOT IN (\n",
    "        SELECT DISTINCT acc from nih-sra-datastore.sra_tax_analysis_tool.tax_analysis\n",
    "        JOIN rnalab-393418.stat_accessions.existing_accessions \n",
    "        USING(acc)\n",
    "    )\n",
    "    ORDER BY acc\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query) \n",
    "\n",
    "\n",
    "cur_row_id = get_max_row_id() + 1\n",
    "stats_data = []\n",
    "batch = 0\n",
    "\n",
    "def write_stat_data_to_csv(stats_data, batch):\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    filename = f\"stat_download/stat_missing_{batch}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    df = None\n",
    "    gc.collect()\n",
    "\n",
    "for row in query_job:\n",
    "    stats_data.append({\n",
    "        'row_id': cur_row_id,\n",
    "        'run': row['acc'],\n",
    "        'taxid': row['tax_id'],\n",
    "        'rank': row['rank'],\n",
    "        'name': row['name'],\n",
    "        'kmer': row['total_count'],\n",
    "    })\n",
    "    cur_row_id += 1\n",
    "    if len(stats_data) % 1000000 == 0:\n",
    "        print(batch)\n",
    "        write_stat_data_to_csv(stats_data, batch)\n",
    "        batch += 1\n",
    "        stats_data = []\n",
    "        gc.collect()\n",
    "\n",
    "write_stat_data_to_csv(stats_data, batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update sra_stat table with all missing runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 126.50 s\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(os.path.join('stat_download', '*.csv'))\n",
    "ddf_stat = dd.read_csv(filenames)\n",
    "ddf_stat = ddf_stat.set_index('run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####                                    ] | 10% Completed | 25.14 ss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m ddf_stat \u001b[39m=\u001b[39m compute_kmer_perc(ddf_stat)\n\u001b[1;32m      3\u001b[0m ddf_stat \u001b[39m=\u001b[39m ddf_stat\u001b[39m.\u001b[39mmerge(\n\u001b[1;32m      4\u001b[0m     stats_tax_labels[[\u001b[39m'\u001b[39m\u001b[39mtaxid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtax_label\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m      5\u001b[0m     left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtaxid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtaxid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m ddf_stat \u001b[39m=\u001b[39m ddf_stat\u001b[39m.\u001b[39mpersist()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/dask/base.py:287\u001b[0m, in \u001b[0;36mDaskMethodsMixin.persist\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpersist\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Persist this dask collection into memory\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[39m    This turns a lazy Dask collection into a Dask collection with the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m    dask.persist\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     (result,) \u001b[39m=\u001b[39m persist(\u001b[39mself\u001b[39m, traverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    288\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/dask/base.py:900\u001b[0m, in \u001b[0;36mpersist\u001b[0;34m(traverse, optimize_graph, scheduler, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m     keys\u001b[39m.\u001b[39mextend(a_keys)\n\u001b[1;32m    898\u001b[0m     postpersists\u001b[39m.\u001b[39mappend((rebuild, a_keys, state))\n\u001b[0;32m--> 900\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    901\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, results))\n\u001b[1;32m    902\u001b[0m results2 \u001b[39m=\u001b[39m [r({k: d[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m ks}, \u001b[39m*\u001b[39ms) \u001b[39mfor\u001b[39;00m r, ks, s \u001b[39min\u001b[39;00m postpersists]\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/dask/local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> 500\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[1;32m    501\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m    502\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/dask/local.py:137\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mqueue_get\u001b[39m(q):\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39mget()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_empty\u001b[39m.\u001b[39mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# enrich_stats_data\n",
    "ddf_stat = compute_kmer_perc(ddf_stat)\n",
    "ddf_stat = ddf_stat.merge(\n",
    "    stats_tax_labels[['taxid', 'tax_label']],\n",
    "    left_on='taxid',\n",
    "    right_on='taxid',\n",
    "    how='left',\n",
    ")\n",
    "ddf_stat = ddf_stat.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 349.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_00.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_01.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_02.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_03.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_04.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_05.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_06.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_07.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_08.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_09.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_10.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_11.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_12.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_13.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_14.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_15.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_16.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_17.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_18.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_19.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_20.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_21.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_22.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_23.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_24.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_25.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_26.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_27.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_28.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_29.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_30.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_31.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_32.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_33.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_34.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_35.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_36.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_37.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_38.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_39.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_40.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_41.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_42.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_43.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_44.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_45.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_46.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_47.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_48.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_49.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_50.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_51.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_52.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_53.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_54.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_55.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_56.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_57.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_58.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_59.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_60.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_61.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_62.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_63.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_64.csv',\n",
       " '/Users/lukepereira/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/tmp_enriched/stat_missing_enriched_65.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_stat.to_csv('stat_enriched/stat_missing_enriched_*.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_from_file(conn, filename):\n",
    "    cursor = conn.cursor()\n",
    "    copy_sql = \"\"\"\n",
    "        COPY sra_stat (run,row_id,taxid,rank,name,kmer,total_kmers,kmer_perc,tax_label)\n",
    "        FROM stdin WITH CSV HEADER\n",
    "        DELIMITER as ','\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        try:\n",
    "            cursor.copy_expert(sql=copy_sql, file=f)\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            cursor.close()\n",
    "            return error\n",
    "    print(\"copy_from_file() done\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_enriched/stat_missing_enriched_00.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_01.csv\n",
      "Error: COPY from stdin failed: error in .read() call\n",
      "CONTEXT:  COPY sra_stat, line 774628\n",
      "\n",
      "tmp_enriched/stat_missing_enriched_02.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_03.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_04.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_05.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_06.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_07.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_08.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_09.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_10.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_11.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_12.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_13.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_14.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_15.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_16.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_17.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_18.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_19.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_20.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_21.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_22.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_23.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_24.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_25.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_26.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_27.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_28.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_29.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_30.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_31.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_32.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_33.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_34.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_35.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_36.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_37.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_38.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_39.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_40.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_41.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_42.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_43.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_44.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_45.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_46.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_47.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_48.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_49.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_50.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_51.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_52.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_53.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_54.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_55.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_56.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_57.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_58.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_59.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_60.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_61.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_62.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_63.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_64.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_65.csv\n",
      "copy_from_file() done\n",
      "tmp_enriched/stat_missing_enriched_66.csv\n",
      "copy_from_file() done\n",
      "[QueryCanceled('COPY from stdin failed: error in .read() call\\nCONTEXT:  COPY sra_stat, line 774628\\n')]\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "conn = get_write_connection()\n",
    "\n",
    "filelist = glob.glob(os.path.join('stat_enriched', '*.csv'))\n",
    "\n",
    "for infile in sorted(filelist):\n",
    "    f = str(infile)\n",
    "    if not os.path.isfile(f):\n",
    "        continue\n",
    "    print(f)\n",
    "    err = copy_from_file(conn, f)\n",
    "    if err:\n",
    "        errs.append(err)\n",
    "\n",
    "print(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up STAT download files and enriched csv files\n",
    "os.rmdir('stat_download')\n",
    "os.rmdir('stat_enriched')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Neo4j with STAT HAS_HOST_METADATA edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob(os.path.join('stat_enriched', '*.csv'))\n",
    "ddf_stat = dd.read_csv(filelist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 38.45 s\n",
      "[########################################] | 100% Completed | 16.49 s\n"
     ]
    }
   ],
   "source": [
    "unique_runs = ddf_stat.run.unique().compute()\n",
    "unique_taxons = ddf_stat.taxid.unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9251170\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_runs))\n",
    "print(len(unique_taxons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m\n\u001b[1;32m     19\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39m        MATCH (t:Taxon)\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[39m        WHERE t.taxId in $tax_ids\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39m        RETURN Collect(DISTINCT t.taxId) as tax_ids\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m conn\u001b[39m.\u001b[39mquery(\n\u001b[1;32m     25\u001b[0m         query,\n\u001b[1;32m     26\u001b[0m         parameters\u001b[39m=\u001b[39m{\n\u001b[1;32m     27\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mtax_ids\u001b[39m\u001b[39m'\u001b[39m: tax_ids,\n\u001b[1;32m     28\u001b[0m         }\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 31\u001b[0m out \u001b[39m=\u001b[39m sanity_check_sras(unique_runs)\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(out)\n\u001b[1;32m     33\u001b[0m missing_runs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(unique_runs) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(out[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrun_ids\u001b[39m\u001b[39m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m, in \u001b[0;36msanity_check_sras\u001b[0;34m(run_ids)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msanity_check_sras\u001b[39m(run_ids):\n\u001b[1;32m      6\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m        MATCH (s:SRA)\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m        WHERE s.runId in $run_ids\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39m        RETURN COLLECT(DISTINCT s.runId) as run_ids\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m conn\u001b[39m.\u001b[39mquery(\n\u001b[1;32m     12\u001b[0m         query,\n\u001b[1;32m     13\u001b[0m         parameters\u001b[39m=\u001b[39m{\n\u001b[1;32m     14\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mrun_ids\u001b[39m\u001b[39m'\u001b[39m: run_ids,\n\u001b[1;32m     15\u001b[0m         }\n\u001b[1;32m     16\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/rna-life/virus-host-graph-db/jobs/etl/notebooks/../datasources/neo4j.py:29\u001b[0m, in \u001b[0;36mNeo4jConnection.query\u001b[0;34m(self, query, parameters, db)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_driver\u001b[39m.\u001b[39msession(\n\u001b[1;32m     28\u001b[0m         database\u001b[39m=\u001b[39mdb) \u001b[39mif\u001b[39;00m db \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_driver\u001b[39m.\u001b[39msession()\n\u001b[0;32m---> 29\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(session\u001b[39m.\u001b[39mrun(query, parameters))\n\u001b[1;32m     30\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mQuery failed:\u001b[39m\u001b[39m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_sync/work/session.py:289\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m bookmarks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bookmarks()\n\u001b[1;32m    288\u001b[0m parameters \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(parameters \u001b[39mor\u001b[39;00m {}, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 289\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_auto_result\u001b[39m.\u001b[39m_run(\n\u001b[1;32m    290\u001b[0m     query, parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mdatabase,\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mimpersonated_user, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mdefault_access_mode,\n\u001b[1;32m    292\u001b[0m     bookmarks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mnotifications_min_severity,\n\u001b[1;32m    293\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mnotifications_disabled_categories,\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    296\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_auto_result\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_sync/work/result.py:152\u001b[0m, in \u001b[0;36mResult._run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attached \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     Util\u001b[39m.\u001b[39mcallback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_closed)\n\u001b[0;32m--> 152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mrun(\n\u001b[1;32m    153\u001b[0m     query_text,\n\u001b[1;32m    154\u001b[0m     parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    155\u001b[0m     mode\u001b[39m=\u001b[39maccess_mode,\n\u001b[1;32m    156\u001b[0m     bookmarks\u001b[39m=\u001b[39mbookmarks,\n\u001b[1;32m    157\u001b[0m     metadata\u001b[39m=\u001b[39mquery_metadata,\n\u001b[1;32m    158\u001b[0m     timeout\u001b[39m=\u001b[39mquery_timeout,\n\u001b[1;32m    159\u001b[0m     db\u001b[39m=\u001b[39mdb,\n\u001b[1;32m    160\u001b[0m     imp_user\u001b[39m=\u001b[39mimp_user,\n\u001b[1;32m    161\u001b[0m     notifications_min_severity\u001b[39m=\u001b[39mnotifications_min_severity,\n\u001b[1;32m    162\u001b[0m     notifications_disabled_categories\u001b[39m=\u001b[39m\n\u001b[1;32m    163\u001b[0m         notifications_disabled_categories,\n\u001b[1;32m    164\u001b[0m     dehydration_hooks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hydration_scope\u001b[39m.\u001b[39mdehydration_hooks,\n\u001b[1;32m    165\u001b[0m     on_success\u001b[39m=\u001b[39mon_attached,\n\u001b[1;32m    166\u001b[0m     on_failure\u001b[39m=\u001b[39mon_failed_attach,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pull()\n\u001b[1;32m    169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39msend_all()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:180\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    179\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m         func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    181\u001b[0m     \u001b[39mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    182\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m asyncio\u001b[39m.\u001b[39miscoroutinefunction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_sync/io/_bolt5.py:501\u001b[0m, in \u001b[0;36mBolt5x2.run\u001b[0;34m(self, query, parameters, mode, bookmarks, metadata, timeout, db, imp_user, notifications_min_severity, notifications_disabled_categories, dehydration_hooks, hydration_hooks, **handlers)\u001b[0m\n\u001b[1;32m    498\u001b[0m fields \u001b[39m=\u001b[39m (query, parameters, extra)\n\u001b[1;32m    499\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39m[#\u001b[39m\u001b[39m%04X\u001b[39;00m\u001b[39m]  C: RUN \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_port,\n\u001b[1;32m    500\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mrepr\u001b[39m, fields)))\n\u001b[0;32m--> 501\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\x10\u001b[39;00m\u001b[39m\"\u001b[39m, fields,\n\u001b[1;32m    502\u001b[0m              Response(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m\"\u001b[39m, hydration_hooks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhandlers),\n\u001b[1;32m    503\u001b[0m              dehydration_hooks\u001b[39m=\u001b[39mdehydration_hooks)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_sync/io/_bolt.py:662\u001b[0m, in \u001b[0;36mBolt._append\u001b[0;34m(self, signature, fields, response, dehydration_hooks)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_append\u001b[39m(\u001b[39mself\u001b[39m, signature, fields\u001b[39m=\u001b[39m(), response\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    651\u001b[0m             dehydration_hooks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    652\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Appends a message to the outgoing queue.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[39m    :param signature: the signature of the message\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m        object of type understood by packstream.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutbox\u001b[39m.\u001b[39mappend_message(signature, fields, dehydration_hooks)\n\u001b[1;32m    663\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponses\u001b[39m.\u001b[39mappend(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:134\u001b[0m, in \u001b[0;36mOutbox.append_message\u001b[0;34m(self, tag, fields, dehydration_hooks)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mappend_message\u001b[39m(\u001b[39mself\u001b[39m, tag, fields, dehydration_hooks):\n\u001b[1;32m    133\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer\u001b[39m.\u001b[39mtmp_buffer():\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packer\u001b[39m.\u001b[39mpack_struct(tag, fields, dehydration_hooks)\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_message()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_codec/packstream/v1/__init__.py:240\u001b[0m, in \u001b[0;36mPacker.pack_struct\u001b[0;34m(self, signature, fields, dehydration_hooks)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpack_struct\u001b[39m(\u001b[39mself\u001b[39m, signature, fields, dehydration_hooks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack_struct(\n\u001b[1;32m    241\u001b[0m         signature, fields,\n\u001b[1;32m    242\u001b[0m         dehydration_hooks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inject_hooks(dehydration_hooks)\n\u001b[1;32m    243\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_codec/packstream/v1/__init__.py:256\u001b[0m, in \u001b[0;36mPacker._pack_struct\u001b[0;34m(self, signature, fields, dehydration_hooks)\u001b[0m\n\u001b[1;32m    254\u001b[0m write(signature)\n\u001b[1;32m    255\u001b[0m \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m fields:\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack(field, dehydration_hooks)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_codec/packstream/v1/__init__.py:161\u001b[0m, in \u001b[0;36mPacker._pack\u001b[0;34m(self, value, dehydration_hooks)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mMap keys must be strings, not \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(key))\n\u001b[1;32m    159\u001b[0m             )\n\u001b[1;32m    160\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack(key, dehydration_hooks)\n\u001b[0;32m--> 161\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack(item, dehydration_hooks)\n\u001b[1;32m    163\u001b[0m \u001b[39m# Structure\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Structure):\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_codec/packstream/v1/__init__.py:150\u001b[0m, in \u001b[0;36mPacker._pack\u001b[0;34m(self, value, dehydration_hooks)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack_list_header(\u001b[39mlen\u001b[39m(value))\n\u001b[1;32m    149\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m value:\n\u001b[0;32m--> 150\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack(item, dehydration_hooks)\n\u001b[1;32m    152\u001b[0m \u001b[39m# Map\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, MAPPING_TYPES):\n",
      "File \u001b[0;32m~/anaconda3/envs/rnalab/lib/python3.11/site-packages/neo4j/_codec/packstream/v1/__init__.py:137\u001b[0m, in \u001b[0;36mPacker._pack\u001b[0;34m(self, value, dehydration_hooks)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m# String\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 137\u001b[0m     encoded \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack_string_header(\u001b[39mlen\u001b[39m(encoded))\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack_raw(encoded)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasources.neo4j import get_connection\n",
    "\n",
    "conn = get_connection()\n",
    "\n",
    "def sanity_check_sras(run_ids):\n",
    "    query = '''\n",
    "        MATCH (s:SRA)\n",
    "        WHERE s.runId in $run_ids\n",
    "        RETURN COLLECT(DISTINCT s.runId) as run_ids\n",
    "    '''\n",
    "    return conn.query(\n",
    "        query,\n",
    "        parameters={\n",
    "            'run_ids': run_ids,\n",
    "        }\n",
    "    )\n",
    "\n",
    "def sanity_check_taxons(tax_ids):\n",
    "    query = '''\n",
    "        MATCH (t:Taxon)\n",
    "        WHERE t.taxId in $tax_ids\n",
    "        RETURN Collect(DISTINCT t.taxId) as tax_ids\n",
    "    '''\n",
    "    return conn.query(\n",
    "        query,\n",
    "        parameters={\n",
    "            'tax_ids': tax_ids,\n",
    "        }\n",
    "    )\n",
    "\n",
    "out = sanity_check_sras(unique_runs)\n",
    "print(out)\n",
    "missing_runs = set(unique_runs) - set(out[0]['run_ids'])\n",
    "print(\"Missing runs\", missing_runs)\n",
    "\n",
    "unique_taxons = [str(x) for x in unique_taxons]\n",
    "out = sanity_check_taxons(unique_taxons)\n",
    "missing_taxons = set(unique_taxons) - set(out[0]['tax_ids'])\n",
    "print(\"Missing taxons\", missing_taxons)\n",
    "\n",
    "# 28883 was merged to 2731619\n",
    "# 206350 was merged to 32003\n",
    "# 1212 was merged to 1213\n",
    "# 40677 was merged to 6132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 1.33 ss\n",
      "[########################################] | 100% Completed | 1.31 ss\n",
      "[########################################] | 100% Completed | 1.34 ss\n",
      "[########################################] | 100% Completed | 1.19 ss\n",
      "[########################################] | 100% Completed | 1.72 ss\n",
      "[########################################] | 100% Completed | 1.20 ss\n",
      "[########################################] | 100% Completed | 1.18 ss\n",
      "[########################################] | 100% Completed | 1.17 ss\n",
      "[########################################] | 100% Completed | 1.23 ss\n",
      "[########################################] | 100% Completed | 1.22 ss\n",
      "[########################################] | 100% Completed | 1.23 ss\n",
      "[########################################] | 100% Completed | 1.06 ss\n",
      "[########################################] | 100% Completed | 1.15 ss\n",
      "[########################################] | 100% Completed | 1.15 ss\n"
     ]
    }
   ],
   "source": [
    "#22933\n",
    "def add_sra_stat_taxon_edges(rows):\n",
    "    query = '''\n",
    "            UNWIND $rows as row\n",
    "            MATCH (s:SRA), (t:Taxon)\n",
    "            WHERE s.runId = toString(row.run)\n",
    "            AND t.taxId = toString(row.taxid)\n",
    "            AND round(toFloat(row.kmer_perc / 100), 4) > 0\n",
    "            MERGE (s)-[r:HAS_HOST_STAT]->(t)\n",
    "            SET r += {\n",
    "                percentIdentity: round(toFloat(row.kmer_perc / 100), 4),\n",
    "                percentIdentityFull: CASE WHEN s.spots > 0 \n",
    "                    THEN round(toFloat(row.kmer) / toFloat(s.spots), 4)\n",
    "                    ELSE 0.0 END,\n",
    "                kmer: row.kmer,\n",
    "                totalKmers: row.total_kmers,\n",
    "                totalSpots: s.spots\n",
    "            }\n",
    "            '''\n",
    "    return graph_queries.batch_insert_data(query, rows)\n",
    "\n",
    "add_sra_stat_taxon_edges(ddf_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "30908\n"
     ]
    }
   ],
   "source": [
    "from datasources.neo4j import get_connection\n",
    "\n",
    "conn = get_connection()\n",
    "\n",
    "def debug_missing_spots(run_ids):\n",
    "    query = '''\n",
    "            MATCH (s:SRA)\n",
    "            WHERE s.runId in $run_ids\n",
    "            AND s.spots = 0\n",
    "            RETURN Collect(DISTINCT s.runId) as run_ids\n",
    "            '''\n",
    "    return conn.query(\n",
    "            query,\n",
    "            parameters={\n",
    "                'run_ids': run_ids,\n",
    "            }\n",
    "        )\n",
    "\n",
    "out = debug_missing_spots(ddf_stat.run.unique())\n",
    "print(len(out[0]['run_ids']))\n",
    "print(len(ddf_stat.run.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temp fix in graph to add missing spots\n",
    "# Long-term fix involves updating sra tables to include missing spots\n",
    "missing_spots = {\n",
    "      'ERR3415775': 27250560,\n",
    "      'ERR4352771': 0,\n",
    "      'ERR1994964': 23972947,\n",
    "      'ERR5384467': 8430905,\n",
    "      'ERR1726732': 0,\n",
    "      'ERR3415759': 27860746,\n",
    "      'ERR3274949': 865925712,\n",
    "      'ERR538188': 0,\n",
    "      'ERR2003549': 23972947,\n",
    "      'ERR3415758': 41826118,\n",
    "      'ERR3415760': 31480217,\n",
    "      'ERR1726762': 0,\n",
    "      'ERR1726702': 0,\n",
    "      'ERR1994972': 23231253,\n",
    "      'ERR1726688': 0,\n",
    "      'ERR3415762': 20223464,\n",
    "      'ERR2003534': 27306569,\n",
    "      'ERR3978063': 60335336,\n",
    "      'ERR3806953': 0,\n",
    "      'ERR3415774': 35643841,\n",
    "      'ERR2003542': 36240950,\n",
    "      'ERR3415773': 39138550,\n",
    "      'ERR538183': 0,\n",
    "      'ERR3415761': 24380142,\n",
    "      'ERR2003547': 23729256,\n",
    "      'ERR1726916': 0,\n",
    "      'ERR1726629': 0,\n",
    "      'ERR1726949': 0,\n",
    "      'ERR2003527': 35611500,\n",
    "      'ERR1994960': 36240950,\n",
    "      'ERR1726891': 0,\n",
    "      'ERR1726944': 0,\n",
    "      'ERR1726740': 0,\n",
    "      'ERR1726724': 0,\n",
    "      'ERR3806950': 0,\n",
    "      'ERR4352608': 0,\n",
    "}\n",
    "\n",
    "missing_spots_df = pd.DataFrame(missing_spots.items(), columns=['runId', 'spots'])\n",
    "\n",
    "missing_spots_ddf = dd.from_pandas(missing_spots_df, chunksize=1000)\n",
    "\n",
    "\n",
    "def add_missing_spots_to_sras(rows):\n",
    "    query = '''\n",
    "            UNWIND $rows as row\n",
    "            MATCH (s:SRA)\n",
    "            WHERE s.runId = row.run \n",
    "            SET s += {\n",
    "                spots: toInteger(row.spots),\n",
    "                spotsWithMates: toInteger(row.spots)\n",
    "            }\n",
    "            '''\n",
    "    return graph_queries.batch_insert_data(query, rows)\n",
    "\n",
    "add_missing_spots_to_sras(missing_spots_ddf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5e03ba6b2b8c2ca14b493d044111ef60b8f39439fa9a5802e41375e2b8bfac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
